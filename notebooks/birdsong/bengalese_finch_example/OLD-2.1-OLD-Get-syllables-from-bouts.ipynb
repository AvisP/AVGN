{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syllabification Notebook\n",
    "- This notebook takes WAV datasets generated by `1.0-segment-song-from-wavs` and segments the WAVs into spectrograms of syllables \n",
    "  - WAVs are expected to be in this format: `2017-04-16_17-27-44-760000.wav`\n",
    "- The notebook outputs and HDF5 file which contains metadata about who the individual is, when the syllable was sung, how long the syllable is, which file the syllable comes from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T21:04:03.007089Z",
     "start_time": "2019-04-25T21:04:02.889776Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:27.079870Z",
     "start_time": "2019-04-25T22:01:23.584918Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import copy\n",
    "from glob import glob\n",
    "\n",
    "from avgn.utils.paths import DATA_DIR, ensure_dir\n",
    "from avgn.utils.general import save_dict_pickle\n",
    "from avgn.signalprocessing.spectrogramming import _build_mel_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for segmenting syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T21:35:50.034167Z",
     "start_time": "2019-04-25T21:35:49.989936Z"
    }
   },
   "outputs": [],
   "source": [
    "# the size of the syllables (pixels*pixels)\n",
    "syll_size = 128\n",
    "\n",
    "# parameters for filtering\n",
    "filtering_params = {\n",
    "    # filtering\n",
    "    \"highcut\": 15000,\n",
    "    \"lowcut\": 500,\n",
    "}\n",
    "\n",
    "spectrogramming_params = {\n",
    "    # spectrograms\n",
    "    \"mel_filter\": True,  # should a mel filter be used?\n",
    "    \"num_mels\": syll_size,  # how many channels to use in the mel-spectrogram\n",
    "    \"num_freq\": 512,  # how many channels to use in a spectrogram\n",
    "    \"num_freq_final\": syll_size,  # how many channels to use in the resized spectrogram\n",
    "    \"sample_rate\": 44100,  # what rate are your WAVs sampled at?\n",
    "    \"preemphasis\": 0.97,\n",
    "    \"min_silence_for_spec\": 0.5,  # minimum length of silence for a spectrogram to be considered a good spectrogram\n",
    "    \"max_vocal_for_spec\": 5.0,  # the longest a single vocalization (protosyllable) is allowed to be\n",
    "    \"frame_shift_ms\": 0.5,  # step size for fft\n",
    "    \"frame_length_ms\": 6,  # frame length for fft\n",
    "    \"min_level_dB\": -80,  # minimum threshold db for computing spe\n",
    "    \"min_level_dB_floor\": -20,  # (db)\n",
    "    \"spec_thresh_delta_dB\": 5,  # (db) what\n",
    "    \"ref_level_dB\": 20,  # reference db for computing spec\n",
    "    \"sample_rate\": 44100,  # sample rate of your data\n",
    "    \"fmin_mel\": 300,  # low frequency cutoff for mel filter\n",
    "    \"fmax_mel\": None,  # high frequency cutoff for mel filter\n",
    "}\n",
    "\n",
    "envelope_params = {\n",
    "    # Vocal Envelope\n",
    "    \"smoothing\": \"gaussian\",  # 'none',\n",
    "    \"envelope_signal\": \"spectrogram\",  # spectrogram or waveform, what to get the vocal envelope from\n",
    "    \"gauss_sigma_s\": 0.0001,\n",
    "    \"FOI_min\": 4,  # minimum frequency of interest for vocal envelope (in terms of mel)\n",
    "    \"FOI_max\": 24,  # maximum frequency of interest for vocal envelope (in terms of mel)\n",
    "}\n",
    "\n",
    "bout_threshold_params = {\n",
    "    # Silence Thresholding\n",
    "    \"silence_threshold\": 0.001,  # normalized threshold for silence\n",
    "    \"min_len\": 5.0,  # minimum length for a vocalization (fft frames)\n",
    "    \"power_thresh\": 0.3,  # Threshold for which a syllable is considered to be quiet weak and is probably noise\n",
    "}\n",
    "\n",
    "syllabification_params = {\n",
    "    # Syllabification\n",
    "    \"min_syll_len_s\": 0.03,  # minimum length for a syllable\n",
    "    \"segmentation_rate\": 0.0,  # 0.125, # rate at which to dynamically raise the segmentation threshold (ensure short syllables)\n",
    "    \"threshold_max\": 0.25,\n",
    "    \"min_num_sylls\": 20,  # min number of syllables to be considered a bout\n",
    "    \"slow_threshold\": 0.0,  # 0.02, # second slower threshold\n",
    "    \"max_size_syll\": syll_size,  # the size of the syllable\n",
    "    \"resize_samp_fr\": int(\n",
    "        syll_size * 5.0\n",
    "    ),  # (frames/s) the framerate of the syllable (in compressed spectrogram time components)\n",
    "    # Sencond pass syllabification\n",
    "    \"second_pass_threshold_repeats\": 50,  # the number of times to repeat the second pass threshold\n",
    "    \"ebr_min\": 0.05,  # expected syllabic rate (/s) low\n",
    "    \"ebr_max\": 0.2,  # expected syllabic rate (/s) high\n",
    "    \"max_thresh\": 0.02,  # maximum pct of syllabic envelope to threshold at in second pass\n",
    "    \"thresh_delta\": 0.005,  # delta change in threshold to match second pass syllabification\n",
    "    \"slow_threshold\": 0.005,  # starting threshold for second pass syllabification\n",
    "}\n",
    "\n",
    "spectrogram_inversion_params = {\n",
    "    # spectrogram inversion\n",
    "    \"max_iters\": 200,\n",
    "    \"griffin_lim_iters\": 60,\n",
    "    \"power\": 1.5,\n",
    "    # Thresholding out noise\n",
    "    \"mel_noise_filt\": 0.15,  # thresholds out low power noise in the spectrum - higher numbers will diminish inversion quality\n",
    "}\n",
    "\n",
    "hparams = {\n",
    "    'species': 'BF'\n",
    "}\n",
    "\n",
    "for d in [\n",
    "    filtering_params,\n",
    "    spectrogramming_params,\n",
    "    envelope_params,\n",
    "    bout_threshold_params,\n",
    "    syllabification_params,\n",
    "    spectrogram_inversion_params,\n",
    "]:\n",
    "    for k, v in d.items():\n",
    "        hparams[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T21:35:50.743430Z",
     "start_time": "2019-04-25T21:35:50.719883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/parameter_dictionaries/2019-04-25_14-35-50_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "# this is used to identify this training instance\n",
    "now_string = datetime.now().strftime(\n",
    "    \"%Y-%m-%d_%H-%M-%S\"\n",
    ")  \n",
    "# save the dictionary so that we can reload it for recovering waveforms\n",
    "dict_save = DATA_DIR / (\"parameter_dictionaries/\" + now_string + \"_dict.pickle\")\n",
    "ensure_dir(dict_save)\n",
    "save_dict_pickle(hparams, dict_save)\n",
    "print(dict_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment bouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:29.760403Z",
     "start_time": "2019-04-25T22:01:29.707451Z"
    }
   },
   "outputs": [],
   "source": [
    "# build a basis function if you are using a mel spectrogram\n",
    "_mel_basis = _build_mel_basis(hparams) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:30.328611Z",
     "start_time": "2019-04-25T22:01:30.278688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird4'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird3'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird9'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird7'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird0'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird8'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird2'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird5'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird10'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/bf_wav/Bird6')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the data bird folders\n",
    "dataset_location =   DATA_DIR / 'bf_wav/'\n",
    "indv_folders = list(dataset_location.glob('*'))\n",
    "indv_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:30.764786Z",
     "start_time": "2019-04-25T22:01:30.692638Z"
    }
   },
   "outputs": [],
   "source": [
    "# where data will be written to\n",
    "data_output_location = DATA_DIR / 'bf_song_syllables/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:31.246958Z",
     "start_time": "2019-04-25T22:01:31.190430Z"
    }
   },
   "outputs": [],
   "source": [
    "# skip creating datasets that already exist\n",
    "skip_existing = False \n",
    "\n",
    "# run through WAVs in parallel\n",
    "parallel = True \n",
    "\n",
    "# how many threads to use if parallel is true\n",
    "n_jobs = 10 \n",
    "\n",
    "# how verbose to make the output of the parallelization (higher = more, 0 = none, >50 output is sent to std.out)\n",
    "verbosity = 5 \n",
    "\n",
    "# visualize the output of the algorithm for optimizing parameters\n",
    "visualize = False \n",
    "\n",
    "# whether to save the dataset\n",
    "save_dataset=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:32.962801Z",
     "start_time": "2019-04-25T22:01:32.904820Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "nex = 10 # how many example wavs to plot\n",
    "\n",
    "# make sure not to save datasets of the example plots\n",
    "if visualize==True: \n",
    "    save_dataset=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:33.936563Z",
     "start_time": "2019-04-25T22:01:33.878609Z"
    }
   },
   "outputs": [],
   "source": [
    "# the fields saved in the HDF5 file \n",
    "key_list = (\n",
    "    'wav_file_names', # Wav file (bout_raw) that the syllable came from\n",
    "    'syllable_spectrograms', # spectrogram of syllable\n",
    "    'syll_start_datetimes', # time that this syllable occured\n",
    "    'syll_start_rel_wav', # time relative to bout file that this \n",
    "    'syllable_lengths' # length of the syllable\n",
    "   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:34.594354Z",
     "start_time": "2019-04-25T22:01:34.552402Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T22:01:36.613264Z",
     "start_time": "2019-04-25T22:01:36.270708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca13af8b853488e823fc756b22c9e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird4 320\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Parallel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-b16e8f39e1f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# loop through each bout wav extracting syllable data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             syllable_data = delayed(\n\u001b[1;32m     30\u001b[0m                 \u001b[0msylls_from_bout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_mel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Parallel' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare the data folder\n",
    "species_dir = data_output_location / hparams[\"species\"]\n",
    "ensure_dir(species_dir)\n",
    "\n",
    "# loop through and make individual datasets\n",
    "for indv_folder in tqdm(indv_folders):\n",
    "\n",
    "    # get the birds name\n",
    "    indv_name = indv_folder.name\n",
    "\n",
    "    # check if the file already exists\n",
    "    individual_dataset_loc = species_dir / (indv_name + \"_\" + str(syll_size) + \".hdf5\")\n",
    "    if os.path.exists(individual_dataset_loc) and skip_existing:\n",
    "        print(\"%s already complete, skipping\" % (indv_name))\n",
    "        continue\n",
    "\n",
    "    # initialize lists of bird information\n",
    "    indv_data = {key: [] for key in key_list}\n",
    "    wav_list = list((indv_folder / \"wavs\").glob(\"*.wav\"))\n",
    "    print(indv_name, len(wav_list))\n",
    "\n",
    "    # if visualizing, make sure only to show a few elements\n",
    "    if visualize == True:\n",
    "        wav_list = wav_list[:nex]\n",
    "\n",
    "    # loop through each bout wav extracting syllable data\n",
    "    if parallel:\n",
    "        with Parallel() as parallel:\n",
    "            syllable_data = delayed(\n",
    "                sylls_from_bout(wav_file, _mel_basis, hparams, visualize=visualize)\n",
    "                for wav_file in tqdm(wav_list)\n",
    "            )\n",
    "    else:\n",
    "        syllable_data = [\n",
    "            sylls_from_bout(wav_file, _mel_basis, hparams, visualize=visualize)\n",
    "            for wav_file in tqdm(wav_list)\n",
    "        ]\n",
    "        \n",
    "    # unpack/flatten data grabbed from loop\n",
    "    for dtype, darray in zip(key_list, list(zip(*syllable_data))):\n",
    "            [indv_data[dtype].extend(element) for element in darray] \n",
    "            indv_data[dtype] = np.array(indv_data[dtype])\n",
    "    \n",
    "    if save_dataset:\n",
    "        save_syllable_dataset(individual_dataset_loc, indv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_data_packed = parallel(\n",
    "                delayed(w2s.process_bout)(wav_file,_mel_basis,hparams=hparams,submode=True, visualize = visualize) \n",
    "                     for wav_file in tqdm(wav_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T20:59:47.377250Z",
     "start_time": "2019-04-25T20:59:38.043Z"
    }
   },
   "outputs": [],
   "source": [
    "import hdbscan \n",
    "from skimage.transform import resize\n",
    "import umap\n",
    "import time \n",
    "import seaborn as sns\n",
    "\n",
    "def plot_with_labels(data, labels, title = '', ax = None, figsize = (9,9)):\n",
    "    palette = sns.color_palette('husl', len(np.unique(labels)))\n",
    "    labs_to_numbers_dict = {l:i for i,l in enumerate(np.unique(labels))}\n",
    "    np.random.shuffle(palette)\n",
    "    colors = [palette[labs_to_numbers_dict[x]] if x >= 0 else (0.75, 0.75, 0.75) for x in np.array(labels)]\n",
    "\n",
    "    if not ax: fig, ax= plt.subplots(nrows=1,ncols=1,figsize=figsize)\n",
    "    ax.scatter(data.T[0], data.T[1],\n",
    "               color=colors, alpha = 1, linewidth= 0, s=5)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    if not ax: plt.show()\n",
    "        \n",
    "def cluster_data(data, algorithm, args, kwds, verbose = True):\n",
    "    \"\"\" Cluster data using arbitrary clustering algoritm in sklearn\n",
    "    \"\"\"\n",
    "    # Function modified from HDBSCAN python package website\n",
    "    start_time = time.time()\n",
    "    labels = algorithm(*args, **kwds).fit_predict(data)\n",
    "    end_time = time.time()\n",
    "    if verbose: print('Clustering took {:.2f} s'.format(end_time - start_time))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parallel:\n",
    "    with Parallel() as parallel:\n",
    "        results = delayed(myfunction(myarguments) for myitems in mylist)\n",
    "else:\n",
    "    results = [myfunction(myarguments) for myitems in mylist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(myfunction, mylist, myarguments, myitems, parallel=True):\n",
    "    if parallel:\n",
    "        with Parallel() as parallel:\n",
    "            results = delayed(myfunction(myarguments) for myitems in mylist)\n",
    "    else:\n",
    "        results = [myfunction(myarguments) for myitems in mylist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-25T20:59:47.378616Z",
     "start_time": "2019-04-25T20:59:38.052Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key_list = (\n",
    "            'all_bird_wav_file', # Wav file (bout_raw) that the syllable came from\n",
    "            'all_bird_syll', # spectrogram of syllable\n",
    "            'all_bird_syll_start', # time that this syllable occured\n",
    "            'all_bird_t_rel_to_file', # time relative to bout file that this \n",
    "            'all_bird_syll_lengths' # length of the syllable\n",
    "           ) \n",
    "\n",
    "for bird_folder in tqdm(bird_folders):\n",
    "    bird_name = bird_folder.split('/')[-1]\n",
    "    print(bird_name)\n",
    "\n",
    "    # prepare the data folder\n",
    "    if not os.path.exists(''.join([data_output_location,species,'/'])):\n",
    "        os.makedirs(''.join([data_output_location,species,'/'])) \n",
    "    output_filename = ''.join([data_output_location,species,'/',bird_name,'_'+str(syll_size)+'.hdf5'])\n",
    "    if os.path.exists(output_filename) and skip_existing:\n",
    "        print('%s already complete, skipping' % (bird_name))\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # initialize lists of bird information\n",
    "    bird_data = {key : [] for key in key_list}\n",
    "    wav_list = glob(bird_folder + '/wavs/*.wav')\n",
    "    print(bird_name, len(wav_list))\n",
    "    \n",
    "    if visualize==True: wav_list = wav_list[:nex]\n",
    "\n",
    "    # Syllabify/create dataset\n",
    "    if parallel:\n",
    "        with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "            bird_data_packed = parallel(\n",
    "                delayed(w2s.process_bout)(wav_file,_mel_basis,hparams=hparams,submode=True, visualize = visualize) \n",
    "                     for wav_file in tqdm(wav_list))\n",
    "    else:\n",
    "        bird_data_packed = [w2s.process_bout(wav_file,_mel_basis, hparams=hparams,submode=True, visualize = visualize) for wav_file in tqdm(wav_list)]\n",
    "    \n",
    "    if np.sum([i[0] != [] for i in bird_data_packed]) == 0:\n",
    "        print('Bird had no good bouts')\n",
    "        continue\n",
    "        \n",
    "    for dtype, darray in zip(key_list, list(zip(*bird_data_packed))):\n",
    "            [bird_data[dtype].extend(element) for element in darray] # flatten and clear darray -> bird_data[dtype]\n",
    "            bird_data[dtype] = np.array(bird_data[dtype])\n",
    "\n",
    "    # reformat bird syllables\n",
    "    print('len dataset: ', len(bird_data['all_bird_syll_lengths']))\n",
    "    \n",
    "    # embed\n",
    "    x = bird_data['all_bird_syll'].reshape((len(bird_data['all_bird_syll']), syll_size,syll_size))\n",
    "\n",
    "    x_small = [resize(i, [16,16]) for i in tqdm(x)]\n",
    "    x_small = np.array(x_small).reshape((len(x_small), np.prod(np.shape(x_small)[1:])))\n",
    "    x_small = [(i*255).astype('uint8') for i in x_small]\n",
    "\n",
    "    z = umap.UMAP(\n",
    "        n_neighbors=30,\n",
    "        #min_dist=0.0,\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "    ).fit_transform(x_small)\n",
    "    #label\n",
    "    labels = cluster_data(z,\n",
    "          hdbscan.HDBSCAN,\n",
    "          (),\n",
    "          {'min_cluster_size':100,  'min_samples':1},\n",
    "         verbose = True)\n",
    "    # plot clusters\n",
    "    plot_with_labels(np.array(list(z)), labels, figsize=(20,20))\n",
    "    plt.show()\n",
    "\n",
    "    if save:\n",
    "        w2s.save_dataset(output_filename, \n",
    "                     bird_data['all_bird_syll'], \n",
    "                     bird_data['all_bird_syll_start'].astype('object'),\n",
    "                     bird_data['all_bird_syll_lengths'], \n",
    "                     bird_data['all_bird_wav_file'].astype('object'),\n",
    "                     bird_data['all_bird_t_rel_to_file'],\n",
    "                     bird_name\n",
    "                    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "924px",
    "left": "1162px",
    "right": "20px",
    "top": "120px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
