{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syllabification Notebook\n",
    "- This notebook takes WAV datasets generated by `1.0-segment-song-from-wavs` and segments the WAVs into syllables \n",
    "  - WAVs are expected to be in this format: `2017-04-16_17-27-44-760000.wav`\n",
    "- The notebook outputs a textgrid file corresponding to each wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:15:16.945246Z",
     "start_time": "2019-04-26T06:15:16.928244Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:15:17.385605Z",
     "start_time": "2019-04-26T06:15:16.947033Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:15:21.082755Z",
     "start_time": "2019-04-26T06:15:17.387428Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import copy\n",
    "from glob import glob\n",
    "\n",
    "from avgn.utils.paths import DATA_DIR, ensure_dir\n",
    "from avgn.utils.general import save_dict_pickle\n",
    "from avgn.signalprocessing.spectrogramming import _build_mel_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for segmenting syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:15:21.133814Z",
     "start_time": "2019-04-26T06:15:21.085043Z"
    }
   },
   "outputs": [],
   "source": [
    "# the size of the syllables (pixels*pixels)\n",
    "syll_size = 128\n",
    "\n",
    "# parameters for filtering\n",
    "filtering_params = {\n",
    "    # filtering\n",
    "    \"highcut\": 15000,\n",
    "    \"lowcut\": 500,\n",
    "}\n",
    "\n",
    "spectrogramming_params = {\n",
    "    # spectrograms\n",
    "    \"mel_filter\": False,  # should a mel filter be used?\n",
    "    \"num_freq\": 512,  # how many channels to use in a spectrogram\n",
    "    \"sample_rate\": 44100,  # what rate are your WAVs sampled at?\n",
    "    \"preemphasis\": 0.97,\n",
    "    \"min_silence_for_spec\": 0.5,  # minimum length of silence for a spectrogram to be considered a good spectrogram\n",
    "    \"max_vocal_for_spec\": 5.0,  # the longest a single vocalization (protosyllable) is allowed to be\n",
    "    \"frame_shift_ms\": 0.5,  # step size for fft\n",
    "    \"frame_length_ms\": 6,  # frame length for fft\n",
    "    \"min_level_dB\": -70,  # minimum threshold db for computing spe\n",
    "    \"min_level_dB_floor\": -20,  # (db)\n",
    "    \"spec_thresh_delta_dB\": 5,  # (db) what\n",
    "    \"ref_level_dB\": 20,  # reference db for computing spec\n",
    "    \"sample_rate\": 44100,  # sample rate of your data\n",
    "}\n",
    "\n",
    "envelope_params = {\n",
    "    # Vocal Envelope\n",
    "    \"smoothing\": \"gaussian\",  # 'none',\n",
    "    \"envelope_signal\": \"spectrogram\",  # spectrogram or waveform, what to get the vocal envelope from\n",
    "    \"gauss_sigma_s\": 0.0001,\n",
    "    \"FOI_min\": 4,  # minimum frequency of interest for vocal envelope (in terms of mel)\n",
    "    \"FOI_max\": 24,  # maximum frequency of interest for vocal envelope (in terms of mel)\n",
    "}\n",
    "\n",
    "bout_threshold_params = {\n",
    "    # Silence Thresholding\n",
    "    \"silence_threshold\": 0.001,  # normalized threshold for silence\n",
    "    \"min_len\": 5.0,  # minimum length for a vocalization (fft frames)\n",
    "    \"power_thresh\": 0.3,  # Threshold for which a syllable is considered to be quiet weak and is probably noise\n",
    "}\n",
    "\n",
    "syllabification_params = {\n",
    "    # Syllabification\n",
    "    \"min_syll_len_s\": 0.03,  # minimum length for a syllable\n",
    "    \"segmentation_rate\": 0.0,  # 0.125, # rate at which to dynamically raise the segmentation threshold (ensure short syllables)\n",
    "    \"min_num_sylls\": 20,  # min number of syllables to be considered a bout\n",
    "}\n",
    "\n",
    "hparams = {\"species\": \"BF\", \"dataset\": \"Koumura_Okanoya\"}\n",
    "for d in [\n",
    "    filtering_params,\n",
    "    spectrogramming_params,\n",
    "    envelope_params,\n",
    "    bout_threshold_params,\n",
    "    syllabification_params,\n",
    "]:\n",
    "    for k, v in d.items():\n",
    "        hparams[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:15:21.253835Z",
     "start_time": "2019-04-26T06:15:21.135811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/parameter_dictionaries/2019-04-25_23-27-14_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "# this is used to identify this training instance\n",
    "now_string = datetime.now().strftime(\n",
    "    \"%Y-%m-%d_%H-%M-%S\"\n",
    ")  \n",
    "# save the dictionary so that we can reload it for recovering waveforms\n",
    "dict_save = DATA_DIR / (\"parameter_dictionaries/\" + now_string + \"_dict.pickle\")\n",
    "ensure_dir(dict_save)\n",
    "save_dict_pickle(hparams, dict_save)\n",
    "print(dict_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment bouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:18:52.741033Z",
     "start_time": "2019-04-26T06:18:52.402175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/BF/Koumura_Okanoya/bouts/Bird9'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/BF/Koumura_Okanoya/bouts/Bird3'),\n",
       " PosixPath('/mnt/cube/tsainbur/Projects/github_repos/AVGN_419/AVGN/data/BF/Koumura_Okanoya/bouts/Bird4')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the data bird folders\n",
    "dataset_location = DATA_DIR / hparams['species'] / hparams['dataset'] / 'bouts'\n",
    "indv_folders = list(dataset_location.glob('*'))\n",
    "indv_folders[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:18:52.830837Z",
     "start_time": "2019-04-26T06:18:52.743292Z"
    }
   },
   "outputs": [],
   "source": [
    "# skip creating datasets that already exist\n",
    "skip_existing = False \n",
    "\n",
    "# run through WAVs in parallel\n",
    "parallel = True \n",
    "verbosity = 10 # how verbose parallel should be\n",
    "n_jobs = 10 # how many jobs to run in parallel\n",
    "\n",
    "# visualize the output of the algorithm for optimizing parameters\n",
    "visualize = False \n",
    "\n",
    "# whether to save the dataset\n",
    "save_dataset=True \n",
    "\n",
    "# whether or not to output text for debugging\n",
    "verbose = False\n",
    "\n",
    "# visualization\n",
    "nex = 10 # how many example wavs to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T06:18:53.048392Z",
     "start_time": "2019-04-26T06:18:52.832726Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from avgn.bout_segmentation.dynamic_threshold_segmentation import textgrid_from_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-26T06:18:52.840Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127beb75798346309f6d03442e8c3b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d4c71a15d04937b02a227a4593246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=154), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7ff4f00dff10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\", line 226, in __iter__\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n",
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7ff4f0019728>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\", line 226, in __iter__\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n",
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7ff4f00dff10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\", line 226, in __iter__\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n"
     ]
    }
   ],
   "source": [
    "# loop through and make individual datasets\n",
    "for indv_folder in tqdm(indv_folders):\n",
    "\n",
    "    # get the birds name\n",
    "    indv_name = indv_folder.name\n",
    "    print(indv_name)\n",
    "\n",
    "    # check if the file already exists\n",
    "    textgrid_loc = indv_folder / \"TextGrids\"\n",
    "    ensure_dir(textgrid_loc)\n",
    "\n",
    "    # get wav_list\n",
    "    wav_list = list((indv_folder / \"wavs\").glob(\"*.wav\"))\n",
    "\n",
    "    # if visualizing, make sure only to show a few elements\n",
    "    if visualize == True:\n",
    "        wav_list = wav_list[:nex]\n",
    "\n",
    "    # loop through each bout wav extracting syllable data\n",
    "    if parallel:\n",
    "        with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "            syllable_data = parallel(\n",
    "                delayed(textgrid_from_wav)(\n",
    "                    wav_file,\n",
    "                    textgrid_loc / (wav_file.stem + \".TextGrid\"),\n",
    "                    hparams,\n",
    "                    visualize=visualize,\n",
    "                    verbose=verbose,\n",
    "                )\n",
    "                for wav_file in tqdm(wav_list)\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        syllable_data = [\n",
    "            textgrid_from_wav(\n",
    "                wav_file,\n",
    "                textgrid_loc / (wav_file.stem + \".TextGrid\"),\n",
    "                hparams,\n",
    "                visualize=visualize,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "            for wav_file in tqdm(wav_list)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "924px",
    "left": "1162px",
    "right": "20px",
    "top": "120px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
