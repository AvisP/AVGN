{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:46.411810Z",
     "start_time": "2019-05-05T20:32:46.409589Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/lstm-autoencoders/\n",
    "# https://github.com/gentnerlab/buckeye/blob/master/buckeye_seq2seq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:51.170013Z",
     "start_time": "2019-05-05T20:32:46.413472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.autonotebook import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:51.181826Z",
     "start_time": "2019-05-05T20:32:51.173246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:51.303878Z",
     "start_time": "2019-05-05T20:32:51.186250Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_results(model, dataset):\n",
    "    x_batch = next(iter(dataset))\n",
    "    z = model.encode(x_batch)\n",
    "    x_recon = model.decode(z)\n",
    "    nex = 10\n",
    "    fig, axs = plt.subplots(nrows = 2, ncols=nex, figsize=(nex*2, 4))\n",
    "    for i in range(nex):\n",
    "        axs[0,i].matshow(x_recon.numpy()[i].squeeze(), vmin=0, vmax = 1, cmap = plt.cm.Greys)\n",
    "        axs[1,i].matshow(x_batch.numpy()[i].squeeze(), vmin=0, vmax = 1, cmap = plt.cm.Greys)\n",
    "        axs[0,i].axis('off')\n",
    "        axs[1,i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:57.119906Z",
     "start_time": "2019-05-05T20:32:51.307517Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.networks.test_datasets import load_fashion_MNIST\n",
    "# get the datasets\n",
    "ds, test_dataset = load_fashion_MNIST(TRAIN_BUF=60000, BATCH_SIZE=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:57.125276Z",
     "start_time": "2019-05-05T20:32:57.122364Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 7\n",
    "ndims = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:57.217016Z",
     "start_time": "2019-05-05T20:32:57.127399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:57.306979Z",
     "start_time": "2019-05-05T20:32:57.218774Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    RepeatVector,\n",
    "    Dense,\n",
    "    TimeDistributed,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Reshape,\n",
    ")  # , LSTM\n",
    "from tensorflow.python.keras.layers.recurrent import UnifiedLSTM as LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:57.404276Z",
     "start_time": "2019-05-05T20:32:57.310840Z"
    }
   },
   "outputs": [],
   "source": [
    "class seq2seq_autoencoder(tf.keras.Model):\n",
    "    \"\"\" an autoencoder based on LSTM \n",
    "    Extends:\n",
    "        tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(seq2seq_autoencoder, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.enc = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\",\n",
    "                ),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\",\n",
    "                ),\n",
    "                Reshape(target_shape=(7, 7 * 64)),\n",
    "                LSTM(units=100, activation=\"relu\"),\n",
    "                Dense(units=100),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dec = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(units=100),\n",
    "                RepeatVector(seq_len),\n",
    "                LSTM(units=100, activation=\"relu\", return_sequences=True),\n",
    "                TimeDistributed(Dense(7 * 64)),\n",
    "                Reshape(target_shape=(7, 7, 64)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    padding=\"SAME\",\n",
    "                    activation=\"sigmoid\",\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    padding=\"SAME\",\n",
    "                    activation=\"sigmoid\",\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1,\n",
    "                    kernel_size=3,\n",
    "                    strides=(1, 1),\n",
    "                    padding=\"SAME\",\n",
    "                    activation=\"sigmoid\",\n",
    "                ),\n",
    "                Reshape(target_shape=(28, 28, 1)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function   \n",
    "    def encode(self, x):\n",
    "        return self.enc(x)\n",
    "    @tf.function\n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        z = self.encode(x)\n",
    "        _x = self.decode(z)\n",
    "        ae_loss = tf.reduce_mean(tf.square(x - _x))\n",
    "        return ae_loss\n",
    "\n",
    "    @tf.function\n",
    "    def compute_gradients(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        ### pass through network\n",
    "        with tf.GradientTape() as tape:\n",
    "            ae_loss = self.compute_loss(x)\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(ae_loss, self.trainable_variables)\n",
    "\n",
    "        return gradients\n",
    "\n",
    "    @tf.function\n",
    "    def apply_gradients(self, gradients):\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "    def train(self, train_dataset):\n",
    "        for train_x in tqdm(train_dataset, leave=False):\n",
    "            gradients = self.compute_gradients(train_x)\n",
    "            self.apply_gradients(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:57.514818Z",
     "start_time": "2019-05-05T20:32:57.408047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:32:57.628291Z",
     "start_time": "2019-05-05T20:32:57.518726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0505 13:32:57.602119 140327578892032 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fa008582358>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W0505 13:32:57.614114 140327578892032 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fa008526be0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "\n",
    "model = seq2seq_autoencoder(\n",
    "    #enc = enc,\n",
    "    #dec = dec,\n",
    "    optimizer = optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:33:00.756491Z",
     "start_time": "2019-05-05T20:32:57.630137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.enc(next(iter(ds))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:33:01.551270Z",
     "start_time": "2019-05-05T20:33:00.759377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 28, 28, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dec(model.enc(next(iter(ds)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:33:01.558675Z",
     "start_time": "2019-05-05T20:33:01.555834Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-05T20:32:45.985Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574f4a96a5214b4f9d5bd1376161cdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    model.train(train_dataset=ds)\n",
    "    # compute loss\n",
    "    batch_loss = np.sum(model.compute_loss(next(iter(ds))).numpy())\n",
    "    losses.append(batch_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        display.clear_output(wait=False)\n",
    "    # viz results\n",
    "    visualize_results(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-05T20:32:45.988Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-05T20:32:45.992Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_results(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-05T20:32:45.996Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
