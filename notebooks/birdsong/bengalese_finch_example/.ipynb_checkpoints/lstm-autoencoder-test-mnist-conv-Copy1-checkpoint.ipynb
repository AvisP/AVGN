{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:43.755633Z",
     "start_time": "2019-05-05T21:38:43.753209Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/lstm-autoencoders/\n",
    "# https://github.com/gentnerlab/buckeye/blob/master/buckeye_seq2seq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:47.570794Z",
     "start_time": "2019-05-05T21:38:43.757675Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.autonotebook import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:47.577758Z",
     "start_time": "2019-05-05T21:38:47.572879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:47.701935Z",
     "start_time": "2019-05-05T21:38:47.579618Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_results(model, dataset):\n",
    "    x_batch = next(iter(dataset))\n",
    "    z = model.encode(x_batch)\n",
    "    x_recon = model.decode(z)\n",
    "    nex = 10\n",
    "    fig, axs = plt.subplots(nrows = 2, ncols=nex, figsize=(nex*2, 4))\n",
    "    for i in range(nex):\n",
    "        axs[0,i].matshow(x_recon.numpy()[i].squeeze(), vmin=0, vmax = 1, cmap = plt.cm.Greys)\n",
    "        axs[1,i].matshow(x_batch.numpy()[i].squeeze(), vmin=0, vmax = 1, cmap = plt.cm.Greys)\n",
    "        axs[0,i].axis('off')\n",
    "        axs[1,i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:52.897089Z",
     "start_time": "2019-05-05T21:38:47.703798Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.networks.test_datasets import load_fashion_MNIST\n",
    "# get the datasets\n",
    "ds, test_dataset = load_fashion_MNIST(TRAIN_BUF=60000, BATCH_SIZE=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:52.903728Z",
     "start_time": "2019-05-05T21:38:52.900096Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 7\n",
    "ndims = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:53.043178Z",
     "start_time": "2019-05-05T21:38:52.906263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:53.124610Z",
     "start_time": "2019-05-05T21:38:53.046046Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    RepeatVector,\n",
    "    Dense,\n",
    "    TimeDistributed,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Reshape,\n",
    ")  # , LSTM\n",
    "from tensorflow.python.keras.layers.recurrent import UnifiedLSTM as LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:41:13.309518Z",
     "start_time": "2019-05-05T21:41:13.259953Z"
    }
   },
   "outputs": [],
   "source": [
    "class seq2seq_autoencoder(tf.keras.Model):\n",
    "    \"\"\" an autoencoder based on LSTM \n",
    "    Extends:\n",
    "        tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(seq2seq_autoencoder, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.enc_forward = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\",\n",
    "                ),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\",\n",
    "                ),\n",
    "                Reshape(target_shape=(7, 7 * 64)),\n",
    "                LSTM(units=100, activation=\"relu\"),\n",
    "                Dense(units=100),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.enc_backward = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\",\n",
    "                ),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\",\n",
    "                ),\n",
    "                Reshape(target_shape=(7, 7 * 64)),\n",
    "                LSTM(units=100, activation=\"relu\"),\n",
    "                Dense(units=100),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.dec = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(units=100),\n",
    "                RepeatVector(seq_len),\n",
    "                LSTM(units=100, activation=\"relu\", return_sequences=True),\n",
    "                TimeDistributed(Dense(7 * 64)),\n",
    "                Reshape(target_shape=(7, 7, 64)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    padding=\"SAME\",\n",
    "                    activation=\"sigmoid\",\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    padding=\"SAME\",\n",
    "                    activation=\"sigmoid\",\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1,\n",
    "                    kernel_size=3,\n",
    "                    strides=(1, 1),\n",
    "                    padding=\"SAME\",\n",
    "                    activation=\"sigmoid\",\n",
    "                ),\n",
    "                Reshape(target_shape=(28, 28, 1)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function   \n",
    "    def encode(self, x):\n",
    "        z1 = self.enc_forward(x)\n",
    "        z2 = self.enc_backward(tf.reverse(x, axis = [2]))\n",
    "        return tf.concat([z1, z2], axis = 1)\n",
    "    \n",
    "    @tf.function\n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        z = self.encode(x)\n",
    "        _x = self.decode(z)\n",
    "        ae_loss = tf.reduce_mean(tf.square(x - _x))\n",
    "        return ae_loss\n",
    "\n",
    "    @tf.function\n",
    "    def compute_gradients(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        ### pass through network\n",
    "        with tf.GradientTape() as tape:\n",
    "            ae_loss = self.compute_loss(x)\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(ae_loss, self.trainable_variables)\n",
    "\n",
    "        return gradients\n",
    "\n",
    "    @tf.function\n",
    "    def apply_gradients(self, gradients):\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "    def train(self, train_dataset):\n",
    "        for train_x in tqdm(train_dataset, leave=False):\n",
    "            gradients = self.compute_gradients(train_x)\n",
    "            self.apply_gradients(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:41:29.268043Z",
     "start_time": "2019-05-05T21:41:29.226220Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0505 14:41:29.236339 140514000271104 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fcb5c4f1400>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W0505 14:41:29.246952 140514000271104 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fcb5c50a5f8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W0505 14:41:29.254242 140514000271104 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fcb5c567c88>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "\n",
    "model = seq2seq_autoencoder(\n",
    "    #enc = enc,\n",
    "    #dec = dec,\n",
    "    optimizer = optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:41:46.663423Z",
     "start_time": "2019-05-05T21:41:41.824483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, 200])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(next(iter(ds))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:54.021828Z",
     "start_time": "2019-05-05T21:38:43.386Z"
    }
   },
   "outputs": [],
   "source": [
    "model.decode(model.encode(next(iter(ds)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:54.023119Z",
     "start_time": "2019-05-05T21:38:43.393Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:54.024479Z",
     "start_time": "2019-05-05T21:38:43.400Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    model.train(train_dataset=ds)\n",
    "    # compute loss\n",
    "    batch_loss = np.sum(model.compute_loss(next(iter(ds))).numpy())\n",
    "    losses.append(batch_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        display.clear_output(wait=False)\n",
    "    # viz results\n",
    "    visualize_results(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:54.025956Z",
     "start_time": "2019-05-05T21:38:43.407Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:54.027342Z",
     "start_time": "2019-05-05T21:38:43.410Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_results(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:38:54.028729Z",
     "start_time": "2019-05-05T21:38:43.412Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
